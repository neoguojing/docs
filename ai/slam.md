# SLAM

## 术语	
- Frame	一张照片
- KeyFrame	“重要照片”
- Camera Pose	拍照位置 + 朝向
- MapPoint	空间中的一个钉子
- Observation	钉子在某张照片里的像素位置
- Tracking	跟踪相机怎么动
- Mapping	决定钉子在哪
- BA	同时微调“相机”和“钉子”

## 前端（Front-end）/ 视觉里程计（Visual Odometry, VO）
前端的主要任务是估算相邻时刻之间的运动（即局部、短期的位姿变化）。
- 作用： 从连续的传感器数据（如图像帧或激光扫描）中提取特征，并通过匹配这些特征来计算当前时刻相对于前一时刻的位姿变化。
- 特点： 只关注局部，计算速度快，但会累积误差（漂移）。想象您每走一步都有一点微小的偏差，走得越远，累积的总偏差就越大。

## 后端（Back-end）/ 优化（Optimization）
后端的任务是处理前端的误差并优化全局地图和轨迹。
- 作用： 将前端估计的所有位姿和地图数据纳入一个统一的数学框架中，通过图优化等方法，寻找一个最佳的全局解，最大限度地减少累积误差。
- 输入： 前端计算出的所有位姿估计以及回环检测提供的约束信息。
- 输出： 一条平滑、准确的机器人轨迹和一张一致性高的地图。

## 回环检测（Loop Closure Detection）
回环检测是解决 SLAM 漂移问题的关键。
- 作用： 判断机器人是否“回到了一个曾经访问过的地方”。
- 例子： 扫地机器人从客厅出发，绕了一圈又回到了客厅。
- 重要性： 一旦检测到回环，系统就可以知道“当前位置”和“过去某一时刻的位置”实际上是同一个地方。这提供了一个强大的约束，后端的优化器会利用这个约束来纠正整个过程中的累积误差。

## 建图（Mapping）
根据最终优化好的位姿，将传感器数据转化成可用的地图格式。常见的地图类型有：
- 稀疏地图（Feature Map）： 仅包含环境中的特征点（用于定位）。
- 稠密地图（Dense Map）： 包含环境中所有几何信息（如点云地图）。
- 栅格地图（Occupancy Grid Map）： 将环境划分为一个个小格子，标记为“已占据”、“未占据”或“未知”。（常用于扫地机器人导航）。

## 视觉slam
### 通用配置
参数名 (常见),作用,影响
- Camera.fx, Camera.fy",焦距 (Focal Length)，以像素为单位。,影响 3D 投影和三角测量精度。
- Camera.cx, Camera.cy",主点 (Principal Point) 坐标，即图像中心的偏移。,影响 3D 重建的几何中心。
- Camera.k1, Camera.k2, ...",径向/切向畸变系数。,校正图像失真，确保特征点位置的准确性。
- Camera.fps,相机帧率 (Frames per Second)。,决定运动估计的频率，过低可能导致快速运动跟踪失败。
- Camera.width, Camera.height",图像分辨率。,影响图像处理速度和内存占用。
