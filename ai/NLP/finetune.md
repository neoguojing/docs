# 模型微调技术
- https://github.com/huggingface/peft
## LoRA 低秩适应大型语言模型
- 它通过利用低秩矩阵分解来减少微调过程中的计算和内存需求
- 通过将语言模型的权重矩阵进行低秩分解来解决这个问题
- 进行微调时，只需要更新低秩分解后得到的因子矩阵，相比于更新完整的权重矩阵，这需要更少的计算和内存资源
### 奇异值分解（SVD）是一种常用的低秩分解方法，
- 可以将一个矩阵分解为三个部分：左奇异向量矩阵、奇异值对角矩阵和右奇异向量矩阵的转置
- 优点是能够找到最佳的低秩逼近，并且在计算上相对高效
- 奇异值分解对任何矩阵都有效，甚至适用于非方阵
- https://mp.weixin.qq.com/s?__biz=MzU0MDQ1NjAzNg==&mid=2247539565&idx=3&sn=12e3834d5949f3fb6296910ee1a9fa74&chksm=fb3afe66cc4d7770beac01549e482fd83d88513e8bbd7d127115cedc790d9045976ce27ff2b6&scene=27
### 特征分解（Eigenvalue Decomposition）是另一种常见的低秩分解方法
- 它将一个矩阵分解为特征向量矩阵和特征值对角矩阵的乘积形式
- 特征分解在某些情况下可以提供更好的可解释性
- 特征分解的计算复杂度较高
- 特征分解只对方形矩阵有效

## Accelerate:Hugging Face Pytorch GPU多机多卡加速器
- DeepSpeed

## bitsandbytes
- 轻量级的CUDA自定义函数包装器，特别用于PyTorch中的8位优化器、矩阵乘法（LLM.int8()）和量化函数。
- 8位优化器：bitsandbytes提供了8位优化器，用于在深度学习模型中进行训练和优化。您可以使用8位优化器替换torch.optim中的优化器，并通过修改代码中的相应部分来配置和使用它们。
- LLM.int8()矩阵乘法：bitsandbytes提供了LLM.int8()函数，用于执行8位整数矩阵乘法操作。这种矩阵乘法的目的是在保持计算精度的同时减少内存和计算需求。
- 量化函数：bitsandbytes还提供了一些用于量化和处理数据的函数，以提高模型的效率和性能。
