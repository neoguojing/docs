# 词向量 Word Vecto
词向量是自然语言处理中表示词的数值化表示法,主要的计算方法包括:

## One-hot向量
One-hot向量使用高维稀疏向量来表示词,将词映射到一个大的向量空间中,每个词对应一个索引位置,将该位置设为1,其他位置为0。这种方法可以区分不同词,但没有表征词的语义信息。

## 词频-反文档频率(TF-IDF)
TF-IDF利用词频和反文档频率来表示词的重要程度。词频衡量词在文档中出现的频率,反文档频率衡量词的稀有程度。TF-IDF能反映出词的重要性,但也没有词的语义信息。

## Word2Vec
Word2Vec通过神经网络学习得到词的分布式向量表示,可以表示词的语义信息。主要有CBOW和Skip-Gram两种模型,能学到词的语义类比关系。

## GloVe
GloVe通过统计词与词之间的共现关系生成词向量,也能表示词的语义信息。它利用统计方法和词的全局共现矩阵进行矩阵分解学习词向量。

## BERT
BERT使用大规模无监督语料 pretrain 深层双向语言模型,得到词、句子的语义表示。可 fine-tune 应用到下游NLP任务中。

# 分词
## 分词（Word Segmentation）：
在自然语言处理中，分词是将连续的文本序列切分成一系列有意义的词或标记的过程。分词是基本的文本预处理任务，将连续的字符序列切分为有意义的单词有助于后续的语言理解和处理。
## 子词化（Subword Segmentation）：
子词化是将词或短语进一步切分为更小的单元（子词）的过程。子词化旨在处理词汇中的复杂性，如未登录词、复合词和低频词。通过将单词切分为子词，可以更好地捕捉语言中的内部结构和语义信息。
## 标记：（Token）
是指将文本切分成较小的单位或符号的过程

# 区别和联系
- 标记化是将文本转换为计算机可以处理的形式，以便进行后续的自然语言处理任务
- 词向量它是将单词转换为连续的实数向量，以便进行机器学习和深度学习等任务
- 词向量可以看作是对标记的表示形式之一
- 标记化是在自然语言处理任务的预处理阶段完成的
- 词向量的生成可以是预训练模型或其他词嵌入技术进行的
- 词向量可以用于模型的输入表示，以提供更丰富的语义信息和上下文理解能力
